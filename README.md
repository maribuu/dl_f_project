Веб-приложение для определения степени токсичности текста. На вход подается текст на русском/английском языке, на выходе получаем метку токсичности (non-toxic, insult, obscenity, threat, dangerous) и значение вероятности появление этой метки для введенного текста.

Для работы используется маленькая модель BERT для русского языка ['cointegrated/rubert-tiny-toxicity'](https://huggingface.co/cointegrated/rubert-tiny-toxicity), предобученная для задачи классификации токсичности и неуместности коротких неформальных текстов, таких как комментарии в социальных сетях.

Для взаимодействия с моделью было разработано веб-приложение с помощью фреймворка Flask.
